{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e69c3ae",
   "metadata": {},
   "source": [
    "Создание Task в ClearML для подготовки данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2bb8e4cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClearML Task: created new task id=7588ad37e1014433b1baf96f0c6d8542\n",
      "ClearML results page: https://app.clear.ml/projects/79b0194396f14ec69257352bc2de6e92/experiments/7588ad37e1014433b1baf96f0c6d8542/output/log\n",
      "ClearML Monitor: GPU monitoring failed getting GPU reading, switching off GPU monitoring\n",
      "Загрузка исходного датасета...\n",
      "Исходный датасет: 1008688 строк, 7 столбцов\n",
      "После группировки: 111716 записей\n",
      "Распределение target: {0: 78831, 1: 32885}\n",
      "ClearML results page: https://app.clear.ml/projects/e3f91fd3a0b44ae78fe3cfe96960c30a/experiments/893c6dfcf1bb43b4817e3bd216fe4da8/output/log\n",
      "ClearML dataset page: https://app.clear.ml/datasets/simple/e3f91fd3a0b44ae78fe3cfe96960c30a/experiments/893c6dfcf1bb43b4817e3bd216fe4da8\n",
      "Uploading dataset changes (1 files compressed to 9.89 MiB) to https://files.clear.ml\n",
      "File compression and upload completed: total size 9.89 MiB, 1 chunk(s) stored (average size 9.89 MiB)\n",
      "Создана версия датасета: 893c6dfcf1bb43b4817e3bd216fe4da8\n",
      "ClearML results page: https://app.clear.ml/projects/e3f91fd3a0b44ae78fe3cfe96960c30a/experiments/49e01c0361e0415aacac734065f7247c/output/log\n",
      "ClearML dataset page: https://app.clear.ml/datasets/simple/e3f91fd3a0b44ae78fe3cfe96960c30a/experiments/49e01c0361e0415aacac734065f7247c\n",
      "Uploading dataset changes (1 files compressed to 697.86 KiB) to https://files.clear.ml\n",
      "File compression and upload completed: total size 697.86 KiB, 1 chunk(s) stored (average size 697.86 KiB)\n",
      "Создана версия датасета с предобработанными данными: 49e01c0361e0415aacac734065f7247c\n",
      "Предобработанные данные сохранены как артефакт\n",
      "Task Data_Preparation завершен!\n",
      "Dataset v1 ID: 893c6dfcf1bb43b4817e3bd216fe4da8\n",
      "Dataset v2 ID: 49e01c0361e0415aacac734065f7247c\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from clearml import Task, Dataset\n",
    "\n",
    "# Инициализируем Task для подготовки данных\n",
    "task = Task.init(\n",
    "    project_name='CustomerPropensityTracking',\n",
    "    task_name='Data_Preparation',\n",
    "    task_type=Task.TaskTypes.data_processing\n",
    ")\n",
    "\n",
    "# Логируем информацию о задаче\n",
    "task.set_parameter('dataset_path', '/Users/maximvishnevskiy/ml_practice_7/transactions_diy.csv')\n",
    "task.set_parameter('target_column', 'target')\n",
    "task.set_parameter('target_category', 'Оборудование для сада и дачи')\n",
    "\n",
    "# Загрузка исходных данных\n",
    "logger = task.get_logger()\n",
    "logger.report_text(\"Загрузка исходного датасета...\")\n",
    "\n",
    "df = pd.read_csv('/Users/maximvishnevskiy/ml_practice_7/transactions_diy.csv')\n",
    "logger.report_text(f\"Исходный датасет: {df.shape[0]} строк, {df.shape[1]} столбцов\")\n",
    "\n",
    "# Преобразуем дату\n",
    "df['tr_date'] = pd.to_datetime(df['tr_date'], dayfirst=True)\n",
    "df['year_month'] = df['tr_date'].dt.to_period('M')\n",
    "\n",
    "# Создаем признак целевой категории\n",
    "df['is_garden'] = (df['item_group'] == 'Оборудование для сада и дачи').astype(int)\n",
    "df = df.sort_values(['client', 'tr_date'])\n",
    "\n",
    "# Группировка по клиенту и месяцу\n",
    "client_monthly = df.groupby(['client', 'year_month']).agg(\n",
    "    total_amount=('amount', 'sum'),\n",
    "    purchase_count=('bcode', 'nunique'),\n",
    "    garden_purchase=('is_garden', 'max')\n",
    ").reset_index()\n",
    "\n",
    "# Целевая переменная: покупка в следующем месяце\n",
    "client_monthly['target'] = client_monthly.groupby('client')['garden_purchase'].shift(-1)\n",
    "client_monthly = client_monthly.dropna(subset=['target'])\n",
    "client_monthly['target'] = client_monthly['target'].astype(int)\n",
    "\n",
    "# Логируем статистику\n",
    "logger.report_text(f\"После группировки: {client_monthly.shape[0]} записей\")\n",
    "logger.report_text(f\"Распределение target: {client_monthly['target'].value_counts().to_dict()}\")\n",
    "\n",
    "# Создаем Dataset для версионирования данных\n",
    "dataset = Dataset.create(\n",
    "    dataset_name='CustomerTransactions',\n",
    "    dataset_project='CustomerPropensityTracking'\n",
    ")\n",
    "\n",
    "# Добавляем файлы в Dataset\n",
    "dataset.add_files('/Users/maximvishnevskiy/ml_practice_7/transactions_diy.csv')\n",
    "dataset.upload()\n",
    "\n",
    "# Финализируем первую версию датасета\n",
    "dataset.finalize()\n",
    "logger.report_text(f\"Создана версия датасета: {dataset.id}\")\n",
    "\n",
    "# Сохраняем предобработанные данные\n",
    "preprocessed_path = 'preprocessed_data.csv'\n",
    "client_monthly.to_csv(preprocessed_path, index=False)\n",
    "\n",
    "# Создаем вторую версию датасета с предобработанными данными\n",
    "dataset_v2 = Dataset.create(\n",
    "    dataset_name='CustomerTransactions',\n",
    "    dataset_project='CustomerPropensityTracking',\n",
    "    parent_datasets=[dataset]\n",
    ")\n",
    "\n",
    "dataset_v2.add_files(preprocessed_path)\n",
    "dataset_v2.upload()\n",
    "dataset_v2.finalize()\n",
    "logger.report_text(f\"Создана версия датасета с предобработанными данными: {dataset_v2.id}\")\n",
    "\n",
    "# Логируем артефакт\n",
    "task.upload_artifact('preprocessed_data.csv', artifact_object=preprocessed_path)\n",
    "logger.report_text(\"Предобработанные данные сохранены как артефакт\")\n",
    "\n",
    "# Завершаем задачу\n",
    "task.close()\n",
    "print(\"Task Data_Preparation завершен!\")\n",
    "print(f\"Dataset v1 ID: {dataset.id}\")\n",
    "print(f\"Dataset v2 ID: {dataset_v2.id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6157a97",
   "metadata": {},
   "source": [
    "Цель Task подготовки данных: создание отдельного эксперимента в ClearML для предобработки сырых данных, версионирования датасетов и сохранения артефактов.\n",
    "\n",
    "Выполненные действия:\n",
    "\n",
    "Загрузка исходного датасета transactions_diy.csv (1 008 688 строк, 7 столбцов)\n",
    "\n",
    "Преобразование даты, создание признака is_garden для целевой категории\n",
    "\n",
    "Агрегация данных по клиентам и месяцам\n",
    "\n",
    "Создание целевой переменной target (покупка в следующем месяце)\n",
    "\n",
    "Версионирование:\n",
    "\n",
    "Dataset v1 (ID: 893c6dfcf1bb43b4817e3bd216fe4da8) — исходные данные\n",
    "\n",
    "Dataset v2 (ID: 49e01c0361e0415aacac734065f7247c) — предобработанные данные\n",
    "\n",
    "Сохранение предобработанных данных как артефакта Task\n",
    "\n",
    "Скриншоты для пояснительной записки (сделайте их из веб-интерфейса ClearML):\n",
    "\n",
    "Страница Task Data_Preparation (обзор)\n",
    "\n",
    "Вкладка Artifacts (с прикреплённым файлом preprocessed_data.csv)\n",
    "\n",
    "Раздел Datasets с двумя версиями датасета"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db3679b",
   "metadata": {},
   "source": [
    "Создание первого ML-эксперимента (модель 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0c7f302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Загрузка предобработанных данных из Dataset v2...\n",
      "Загружено 111716 записей, 6 признаков\n",
      "Столбцы в данных: ['client', 'year_month', 'total_amount', 'purchase_count', 'garden_purchase', 'target']\n",
      "Первые 3 строки данных:\n",
      "       client year_month  total_amount  purchase_count  garden_purchase  \\\n",
      "0   client100    2019-05          7299               1                1   \n",
      "1  client1000    2018-09          4336               2                0   \n",
      "2  client1000    2018-10           454               1                0   \n",
      "\n",
      "   target  \n",
      "0       0  \n",
      "1       0  \n",
      "2       0  \n",
      "Train: (78201, 3), Val: (16757, 3), Test: (16758, 3)\n",
      "Гиперпараметры модели: RandomForestClassifier, {'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 2, 'random_state': 42, 'class_weight': 'balanced'}\n",
      "Обучение RandomForest...\n",
      "Метрики на валидации: {'accuracy': 0.6991704959121561, 'f1': np.float64(0.5003469124789375), 'roc_auc': np.float64(0.6727749301915409)}\n",
      "Модель сохранена как randomforest_model_v1.pkl и загружена как артефакт\n",
      "Метрики на тесте: {'accuracy': 0.7029478458049887, 'f1': np.float64(0.5020008003201281), 'roc_auc': np.float64(0.6695023759356644)}\n",
      "ML Experiment 1 завершен!\n",
      "Task ID: 68f5375529a044699d30295668dd7669\n",
      "ROC-AUC на валидации: 0.6728\n",
      "ROC-AUC на тесте: 0.6695\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "МL-эксперимент 1: Бинарная классификация с помощью RandomForest\n",
    "Используется вторая версия датасета (предобработанные данные)\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score, f1_score, accuracy_score\n",
    "import joblib\n",
    "from clearml import Task, Dataset\n",
    "\n",
    "# === 1. Инициализация Task в ClearML ===\n",
    "task = Task.init(\n",
    "    project_name='CustomerPropensityTracking',\n",
    "    task_name='ML_Experiment_1_RandomForest',\n",
    "    task_type=Task.TaskTypes.training\n",
    ")\n",
    "\n",
    "# === 2. Загрузка данных через Dataset (версия 2) ===\n",
    "logger = task.get_logger()\n",
    "logger.report_text(\"Загрузка предобработанных данных из Dataset v2...\")\n",
    "\n",
    "# Получаем Dataset по ID (версия 2 с предобработанными данными)\n",
    "dataset_v2 = Dataset.get(dataset_id='49e01c0361e0415aacac734065f7247c')\n",
    "dataset_path = dataset_v2.get_local_copy()\n",
    "\n",
    "# Загружаем предобработанные данные\n",
    "df = pd.read_csv(f'{dataset_path}/preprocessed_data.csv')\n",
    "logger.report_text(f\"Загружено {df.shape[0]} записей, {df.shape[1]} признаков\")\n",
    "\n",
    "# === 3. Подготовка признаков и целевой переменной ===\n",
    "# Убираем нечисловые колонки\n",
    "X = df.drop(columns=['client', 'year_month', 'target', 'year_month_str'], errors='ignore')\n",
    "y = df['target']\n",
    "print(\"Столбцы в данных:\", df.columns.tolist())\n",
    "print(\"Первые 3 строки данных:\")\n",
    "print(df.head(3))\n",
    "# Разделение на train/val/test (уже было выполнено ранее, но сделаем явно)\n",
    "# Используем временное разделение по месяцам\n",
    "if 'year_month_str' in df.columns:\n",
    "    # Берём последний месяц для теста\n",
    "    test_mask = df['year_month_str'] == df['year_month_str'].max()\n",
    "    train_val_mask = ~test_mask\n",
    "    \n",
    "    X_train_val = X[train_val_mask]\n",
    "    y_train_val = y[train_val_mask]\n",
    "    X_test = X[test_mask]\n",
    "    y_test = y[test_mask]\n",
    "    \n",
    "    # Разделяем train/val\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_train_val, y_train_val, test_size=0.2, random_state=42, stratify=y_train_val\n",
    "    )\n",
    "else:\n",
    "    # Если нет временной метки, используем обычное разделение\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "logger.report_text(f\"Train: {X_train.shape}, Val: {X_val.shape}, Test: {X_test.shape}\")\n",
    "\n",
    "# === 4. Логирование гиперпараметров ===\n",
    "hyperparams = {\n",
    "    'n_estimators': 100,\n",
    "    'max_depth': 10,\n",
    "    'min_samples_split': 5,\n",
    "    'min_samples_leaf': 2,\n",
    "    'random_state': 42,\n",
    "    'class_weight': 'balanced'\n",
    "}\n",
    "\n",
    "# Явно логируем гиперпараметры в ClearML\n",
    "task.connect(hyperparams)\n",
    "logger.report_text(f\"Гиперпараметры модели: RandomForestClassifier, {hyperparams}\")\n",
    "\n",
    "# === 5. Обучение модели ===\n",
    "logger.report_text(\"Обучение RandomForest...\")\n",
    "model = RandomForestClassifier(**hyperparams)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# === 6. Логирование метрик ===\n",
    "# Прогнозы и метрики на валидации\n",
    "y_val_pred = model.predict(X_val)\n",
    "y_val_proba = model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "val_metrics = {\n",
    "    'accuracy': accuracy_score(y_val, y_val_pred),\n",
    "    'f1': f1_score(y_val, y_val_pred),\n",
    "    'roc_auc': roc_auc_score(y_val, y_val_proba)\n",
    "}\n",
    "\n",
    "for metric_name, metric_value in val_metrics.items():\n",
    "    logger.report_scalar(title='Validation Metrics', series=metric_name, value=metric_value, iteration=0)\n",
    "    task.get_logger().report_single_value(name=f'val_{metric_name}', value=metric_value)\n",
    "\n",
    "logger.report_text(f\"Метрики на валидации: {val_metrics}\")\n",
    "\n",
    "# === 7. Сохранение модели как артефакта ===\n",
    "model_path = 'randomforest_model_v1.pkl'\n",
    "joblib.dump(model, model_path)\n",
    "task.upload_artifact('model', model_path)\n",
    "logger.report_text(f\"Модель сохранена как {model_path} и загружена как артефакт\")\n",
    "\n",
    "# === 8. Тестирование на test set ===\n",
    "y_test_pred = model.predict(X_test)\n",
    "y_test_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "test_metrics = {\n",
    "    'accuracy': accuracy_score(y_test, y_test_pred),\n",
    "    'f1': f1_score(y_test, y_test_pred),\n",
    "    'roc_auc': roc_auc_score(y_test, y_test_proba)\n",
    "}\n",
    "\n",
    "for metric_name, metric_value in test_metrics.items():\n",
    "    logger.report_scalar(title='Test Metrics', series=metric_name, value=metric_value, iteration=0)\n",
    "    task.get_logger().report_single_value(name=f'test_{metric_name}', value=metric_value)\n",
    "\n",
    "logger.report_text(f\"Метрики на тесте: {test_metrics}\")\n",
    "\n",
    "# === 9. Завершение задачи ===\n",
    "task.close()\n",
    "print(\"ML Experiment 1 завершен!\")\n",
    "print(f\"Task ID: {task.task_id}\")\n",
    "print(f\"ROC-AUC на валидации: {val_metrics['roc_auc']:.4f}\")\n",
    "print(f\"ROC-AUC на тесте: {test_metrics['roc_auc']:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
